{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40a438e",
   "metadata": {},
   "source": [
    "# The goal of our web scraping project\n",
    "We would like to build a collection of interesting open-source machine learning projects. Therefore, we will scrape top machine learning projects from this ```Github Collection```.\n",
    "\n",
    "(If this collection is closed in the future, you can find other collections from ```Github > Explore``` page).\n",
    "\n",
    "# Tech we need for this project\n",
    "* __Python__ (version 2.X or 3.X should be okay. I am using Python 3) – The easiest way to install Python on your machine is ```Anaconda```.\n",
    "* __Selenium Webdriver for Google Chrome__: ```Chromedriver``` – Download it and place it anywhere on your machine.\n",
    "* __Python Libraries__ – Install them with Python command line ‘pip install xxx’ or ‘!pip install xxx’ in Jupyter Notebook\n",
    "    * __Selenium Webdriver__ – pip install selenium\n",
    "    * __Pandas__ (For exporting data) – pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c394e2e9",
   "metadata": {},
   "source": [
    "# Step 1 Import Selenium Webdriver & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "16ae4da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Di sini kita import semua keperluan terlebih dahulu\n",
    "'''\n",
    "from selenium import webdriver # allow launching browser\n",
    "from selenium.webdriver.common.by import By # allow search with parameters\n",
    "from selenium.webdriver.support.ui import WebDriverWait # allow waiting for page to load\n",
    "from selenium.webdriver.support import expected_conditions as EC # determine whether the web page has loaded\n",
    "from selenium.common.exceptions import TimeoutException # handling timeout situation\n",
    "from selenium.webdriver.chrome.service import Service # To specify the ChromeDriver location because the executable_path argument has been deprecated.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f68f8",
   "metadata": {},
   "source": [
    "Prepare the code for easily opening new browser window (This will be useful when we are doing parallelization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a3c8197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "driver_option = webdriver.ChromeOptions()\n",
    "driver_option.add_argument(\" — incognito\")\n",
    "chromedriver_path = 'e:/chromedriver-win64/chromedriver.exe' # Change this to your own chromedriver path!\n",
    "def create_webdriver():\n",
    " return webdriver.Chrome(executable_path=chromedriver_path, chrome_options=driver_option)\n",
    "\n",
    " Ini yg original, tapi sdh gk bisa karena inisialisasi webdriver.Chrome() sudah berubah. di versi terbaru selenium.\n",
    "'''\n",
    "def create_webdriver():\n",
    " chromedriver_path = 'e:/chromedriver-win64/chromedriver.exe' # Change this to your own chromedriver path!\n",
    " service = Service(chromedriver_path) # Memulai/menghentikan chromedriver\n",
    " driver_option = webdriver.ChromeOptions() # Object dibuat untuk diutak-atik nantinya\n",
    " driver_option.add_argument(\" — incognito\") # Membuka chrome browser yg incognito\n",
    " return webdriver.Chrome(service= service, options=driver_option) # mengembalikan hasil dari perintah di atas\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c9acca",
   "metadata": {},
   "source": [
    "Note that you have to change “chromedriver_path=’…’” to the path you are storing Chromedriver. If you don’t know the path, simply drag and drop the folder into Terminal window. It should show the path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e3755c",
   "metadata": {},
   "source": [
    "# Step 2 Open the Github page & Extract the HTML elements we need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f4a76b",
   "metadata": {},
   "source": [
    "We can start scraping by passing the URL to the Webdriver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "65d161be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the website\n",
    "browser = create_webdriver()\n",
    "browser.get(\"https://github.com/collections/machine-learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba34ecfd",
   "metadata": {},
   "source": [
    "There will be a Google Chrome window opens with the URL we specified. This means we open the browser successfully.\n",
    "\n",
    "Next, we would like to extract the name and URL of all projects listed on this page. We can right click on the web page and click ‘__Inspect__‘ to view the underlying HTML of this page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bc2dea",
   "metadata": {},
   "source": [
    "We found that each project has ```h1``` tag with class “h3 ln-condensed”. Therefore, we can extract all projects using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "13d62fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all projects\n",
    "projects = browser.find_elements(By.XPATH, \"//h1[@class='h3 lh-condensed']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c45fb2",
   "metadata": {},
   "source": [
    "The above code will store each ```h1``` elements and their children tags in the list. We can iterate through the list to extract each project’s name and URL using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e545bd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apache / spark': 'https://github.com/apache/spark'}\n",
      "{'apache / spark': 'https://github.com/apache/spark', 'apache / hadoop': 'https://github.com/apache/hadoop'}\n",
      "{'apache / spark': 'https://github.com/apache/spark', 'apache / hadoop': 'https://github.com/apache/hadoop', 'jbhuang0604 / awesome-computer-vision': 'https://github.com/jbhuang0604/awesome-computer-vision'}\n",
      "{'apache / spark': 'https://github.com/apache/spark', 'apache / hadoop': 'https://github.com/apache/hadoop', 'jbhuang0604 / awesome-computer-vision': 'https://github.com/jbhuang0604/awesome-computer-vision', 'GSA / data': 'https://github.com/GSA/data'}\n",
      "{'apache / spark': 'https://github.com/apache/spark', 'apache / hadoop': 'https://github.com/apache/hadoop', 'jbhuang0604 / awesome-computer-vision': 'https://github.com/jbhuang0604/awesome-computer-vision', 'GSA / data': 'https://github.com/GSA/data', 'GoogleTrends / data': 'https://github.com/GoogleTrends/data'}\n",
      "{'apache / spark': 'https://github.com/apache/spark', 'apache / hadoop': 'https://github.com/apache/hadoop', 'jbhuang0604 / awesome-computer-vision': 'https://github.com/jbhuang0604/awesome-computer-vision', 'GSA / data': 'https://github.com/GSA/data', 'GoogleTrends / data': 'https://github.com/GoogleTrends/data', 'nationalparkservice / data': 'https://github.com/nationalparkservice/data'}\n",
      "{'apache / spark': 'https://github.com/apache/spark', 'apache / hadoop': 'https://github.com/apache/hadoop', 'jbhuang0604 / awesome-computer-vision': 'https://github.com/jbhuang0604/awesome-computer-vision', 'GSA / data': 'https://github.com/GSA/data', 'GoogleTrends / data': 'https://github.com/GoogleTrends/data', 'nationalparkservice / data': 'https://github.com/nationalparkservice/data', 'fivethirtyeight / data': 'https://github.com/fivethirtyeight/data'}\n",
      "{'apache / spark': 'https://github.com/apache/spark', 'apache / hadoop': 'https://github.com/apache/hadoop', 'jbhuang0604 / awesome-computer-vision': 'https://github.com/jbhuang0604/awesome-computer-vision', 'GSA / data': 'https://github.com/GSA/data', 'GoogleTrends / data': 'https://github.com/GoogleTrends/data', 'nationalparkservice / data': 'https://github.com/nationalparkservice/data', 'fivethirtyeight / data': 'https://github.com/fivethirtyeight/data', 'beamandrew / medical-data': 'https://github.com/beamandrew/medical-data'}\n",
      "{'apache / spark': 'https://github.com/apache/spark', 'apache / hadoop': 'https://github.com/apache/hadoop', 'jbhuang0604 / awesome-computer-vision': 'https://github.com/jbhuang0604/awesome-computer-vision', 'GSA / data': 'https://github.com/GSA/data', 'GoogleTrends / data': 'https://github.com/GoogleTrends/data', 'nationalparkservice / data': 'https://github.com/nationalparkservice/data', 'fivethirtyeight / data': 'https://github.com/fivethirtyeight/data', 'beamandrew / medical-data': 'https://github.com/beamandrew/medical-data', 'src-d / awesome-machine-learning-on-source-code': 'https://github.com/src-d/awesome-machine-learning-on-source-code'}\n",
      "{'apache / spark': 'https://github.com/apache/spark', 'apache / hadoop': 'https://github.com/apache/hadoop', 'jbhuang0604 / awesome-computer-vision': 'https://github.com/jbhuang0604/awesome-computer-vision', 'GSA / data': 'https://github.com/GSA/data', 'GoogleTrends / data': 'https://github.com/GoogleTrends/data', 'nationalparkservice / data': 'https://github.com/nationalparkservice/data', 'fivethirtyeight / data': 'https://github.com/fivethirtyeight/data', 'beamandrew / medical-data': 'https://github.com/beamandrew/medical-data', 'src-d / awesome-machine-learning-on-source-code': 'https://github.com/src-d/awesome-machine-learning-on-source-code', 'igrigorik / decisiontree': 'https://github.com/igrigorik/decisiontree'}\n",
      "{'apache / spark': 'https://github.com/apache/spark', 'apache / hadoop': 'https://github.com/apache/hadoop', 'jbhuang0604 / awesome-computer-vision': 'https://github.com/jbhuang0604/awesome-computer-vision', 'GSA / data': 'https://github.com/GSA/data', 'GoogleTrends / data': 'https://github.com/GoogleTrends/data', 'nationalparkservice / data': 'https://github.com/nationalparkservice/data', 'fivethirtyeight / data': 'https://github.com/fivethirtyeight/data', 'beamandrew / medical-data': 'https://github.com/beamandrew/medical-data', 'src-d / awesome-machine-learning-on-source-code': 'https://github.com/src-d/awesome-machine-learning-on-source-code', 'igrigorik / decisiontree': 'https://github.com/igrigorik/decisiontree', 'keon / awesome-nlp': 'https://github.com/keon/awesome-nlp'}\n",
      "{'apache / spark': 'https://github.com/apache/spark', 'apache / hadoop': 'https://github.com/apache/hadoop', 'jbhuang0604 / awesome-computer-vision': 'https://github.com/jbhuang0604/awesome-computer-vision', 'GSA / data': 'https://github.com/GSA/data', 'GoogleTrends / data': 'https://github.com/GoogleTrends/data', 'nationalparkservice / data': 'https://github.com/nationalparkservice/data', 'fivethirtyeight / data': 'https://github.com/fivethirtyeight/data', 'beamandrew / medical-data': 'https://github.com/beamandrew/medical-data', 'src-d / awesome-machine-learning-on-source-code': 'https://github.com/src-d/awesome-machine-learning-on-source-code', 'igrigorik / decisiontree': 'https://github.com/igrigorik/decisiontree', 'keon / awesome-nlp': 'https://github.com/keon/awesome-nlp', 'openai / gym': 'https://github.com/openai/gym'}\n",
      "{'apache / spark': 'https://github.com/apache/spark', 'apache / hadoop': 'https://github.com/apache/hadoop', 'jbhuang0604 / awesome-computer-vision': 'https://github.com/jbhuang0604/awesome-computer-vision', 'GSA / data': 'https://github.com/GSA/data', 'GoogleTrends / data': 'https://github.com/GoogleTrends/data', 'nationalparkservice / data': 'https://github.com/nationalparkservice/data', 'fivethirtyeight / data': 'https://github.com/fivethirtyeight/data', 'beamandrew / medical-data': 'https://github.com/beamandrew/medical-data', 'src-d / awesome-machine-learning-on-source-code': 'https://github.com/src-d/awesome-machine-learning-on-source-code', 'igrigorik / decisiontree': 'https://github.com/igrigorik/decisiontree', 'keon / awesome-nlp': 'https://github.com/keon/awesome-nlp', 'openai / gym': 'https://github.com/openai/gym', 'aikorea / awesome-rl': 'https://github.com/aikorea/awesome-rl'}\n",
      "{'apache / spark': 'https://github.com/apache/spark', 'apache / hadoop': 'https://github.com/apache/hadoop', 'jbhuang0604 / awesome-computer-vision': 'https://github.com/jbhuang0604/awesome-computer-vision', 'GSA / data': 'https://github.com/GSA/data', 'GoogleTrends / data': 'https://github.com/GoogleTrends/data', 'nationalparkservice / data': 'https://github.com/nationalparkservice/data', 'fivethirtyeight / data': 'https://github.com/fivethirtyeight/data', 'beamandrew / medical-data': 'https://github.com/beamandrew/medical-data', 'src-d / awesome-machine-learning-on-source-code': 'https://github.com/src-d/awesome-machine-learning-on-source-code', 'igrigorik / decisiontree': 'https://github.com/igrigorik/decisiontree', 'keon / awesome-nlp': 'https://github.com/keon/awesome-nlp', 'openai / gym': 'https://github.com/openai/gym', 'aikorea / awesome-rl': 'https://github.com/aikorea/awesome-rl', 'umutisik / Eigentechno': 'https://github.com/umutisik/Eigentechno'}\n",
      "{'apache / spark': 'https://github.com/apache/spark', 'apache / hadoop': 'https://github.com/apache/hadoop', 'jbhuang0604 / awesome-computer-vision': 'https://github.com/jbhuang0604/awesome-computer-vision', 'GSA / data': 'https://github.com/GSA/data', 'GoogleTrends / data': 'https://github.com/GoogleTrends/data', 'nationalparkservice / data': 'https://github.com/nationalparkservice/data', 'fivethirtyeight / data': 'https://github.com/fivethirtyeight/data', 'beamandrew / medical-data': 'https://github.com/beamandrew/medical-data', 'src-d / awesome-machine-learning-on-source-code': 'https://github.com/src-d/awesome-machine-learning-on-source-code', 'igrigorik / decisiontree': 'https://github.com/igrigorik/decisiontree', 'keon / awesome-nlp': 'https://github.com/keon/awesome-nlp', 'openai / gym': 'https://github.com/openai/gym', 'aikorea / awesome-rl': 'https://github.com/aikorea/awesome-rl', 'umutisik / Eigentechno': 'https://github.com/umutisik/Eigentechno', 'jpmckinney / tf-idf-similarity': 'https://github.com/jpmckinney/tf-idf-similarity'}\n",
      "{'apache / spark': 'https://github.com/apache/spark', 'apache / hadoop': 'https://github.com/apache/hadoop', 'jbhuang0604 / awesome-computer-vision': 'https://github.com/jbhuang0604/awesome-computer-vision', 'GSA / data': 'https://github.com/GSA/data', 'GoogleTrends / data': 'https://github.com/GoogleTrends/data', 'nationalparkservice / data': 'https://github.com/nationalparkservice/data', 'fivethirtyeight / data': 'https://github.com/fivethirtyeight/data', 'beamandrew / medical-data': 'https://github.com/beamandrew/medical-data', 'src-d / awesome-machine-learning-on-source-code': 'https://github.com/src-d/awesome-machine-learning-on-source-code', 'igrigorik / decisiontree': 'https://github.com/igrigorik/decisiontree', 'keon / awesome-nlp': 'https://github.com/keon/awesome-nlp', 'openai / gym': 'https://github.com/openai/gym', 'aikorea / awesome-rl': 'https://github.com/aikorea/awesome-rl', 'umutisik / Eigentechno': 'https://github.com/umutisik/Eigentechno', 'jpmckinney / tf-idf-similarity': 'https://github.com/jpmckinney/tf-idf-similarity', 'scikit-learn-contrib / lightning': 'https://github.com/scikit-learn-contrib/lightning'}\n",
      "{'apache / spark': 'https://github.com/apache/spark', 'apache / hadoop': 'https://github.com/apache/hadoop', 'jbhuang0604 / awesome-computer-vision': 'https://github.com/jbhuang0604/awesome-computer-vision', 'GSA / data': 'https://github.com/GSA/data', 'GoogleTrends / data': 'https://github.com/GoogleTrends/data', 'nationalparkservice / data': 'https://github.com/nationalparkservice/data', 'fivethirtyeight / data': 'https://github.com/fivethirtyeight/data', 'beamandrew / medical-data': 'https://github.com/beamandrew/medical-data', 'src-d / awesome-machine-learning-on-source-code': 'https://github.com/src-d/awesome-machine-learning-on-source-code', 'igrigorik / decisiontree': 'https://github.com/igrigorik/decisiontree', 'keon / awesome-nlp': 'https://github.com/keon/awesome-nlp', 'openai / gym': 'https://github.com/openai/gym', 'aikorea / awesome-rl': 'https://github.com/aikorea/awesome-rl', 'umutisik / Eigentechno': 'https://github.com/umutisik/Eigentechno', 'jpmckinney / tf-idf-similarity': 'https://github.com/jpmckinney/tf-idf-similarity', 'scikit-learn-contrib / lightning': 'https://github.com/scikit-learn-contrib/lightning', 'gwding / draw_convnet': 'https://github.com/gwding/draw_convnet'}\n",
      "{'apache / spark': 'https://github.com/apache/spark', 'apache / hadoop': 'https://github.com/apache/hadoop', 'jbhuang0604 / awesome-computer-vision': 'https://github.com/jbhuang0604/awesome-computer-vision', 'GSA / data': 'https://github.com/GSA/data', 'GoogleTrends / data': 'https://github.com/GoogleTrends/data', 'nationalparkservice / data': 'https://github.com/nationalparkservice/data', 'fivethirtyeight / data': 'https://github.com/fivethirtyeight/data', 'beamandrew / medical-data': 'https://github.com/beamandrew/medical-data', 'src-d / awesome-machine-learning-on-source-code': 'https://github.com/src-d/awesome-machine-learning-on-source-code', 'igrigorik / decisiontree': 'https://github.com/igrigorik/decisiontree', 'keon / awesome-nlp': 'https://github.com/keon/awesome-nlp', 'openai / gym': 'https://github.com/openai/gym', 'aikorea / awesome-rl': 'https://github.com/aikorea/awesome-rl', 'umutisik / Eigentechno': 'https://github.com/umutisik/Eigentechno', 'jpmckinney / tf-idf-similarity': 'https://github.com/jpmckinney/tf-idf-similarity', 'scikit-learn-contrib / lightning': 'https://github.com/scikit-learn-contrib/lightning', 'gwding / draw_convnet': 'https://github.com/gwding/draw_convnet', 'scikit-learn / scikit-learn': 'https://github.com/scikit-learn/scikit-learn'}\n",
      "{'apache / spark': 'https://github.com/apache/spark', 'apache / hadoop': 'https://github.com/apache/hadoop', 'jbhuang0604 / awesome-computer-vision': 'https://github.com/jbhuang0604/awesome-computer-vision', 'GSA / data': 'https://github.com/GSA/data', 'GoogleTrends / data': 'https://github.com/GoogleTrends/data', 'nationalparkservice / data': 'https://github.com/nationalparkservice/data', 'fivethirtyeight / data': 'https://github.com/fivethirtyeight/data', 'beamandrew / medical-data': 'https://github.com/beamandrew/medical-data', 'src-d / awesome-machine-learning-on-source-code': 'https://github.com/src-d/awesome-machine-learning-on-source-code', 'igrigorik / decisiontree': 'https://github.com/igrigorik/decisiontree', 'keon / awesome-nlp': 'https://github.com/keon/awesome-nlp', 'openai / gym': 'https://github.com/openai/gym', 'aikorea / awesome-rl': 'https://github.com/aikorea/awesome-rl', 'umutisik / Eigentechno': 'https://github.com/umutisik/Eigentechno', 'jpmckinney / tf-idf-similarity': 'https://github.com/jpmckinney/tf-idf-similarity', 'scikit-learn-contrib / lightning': 'https://github.com/scikit-learn-contrib/lightning', 'gwding / draw_convnet': 'https://github.com/gwding/draw_convnet', 'scikit-learn / scikit-learn': 'https://github.com/scikit-learn/scikit-learn', 'tensorflow / tensorflow': 'https://github.com/tensorflow/tensorflow'}\n",
      "{'apache / spark': 'https://github.com/apache/spark', 'apache / hadoop': 'https://github.com/apache/hadoop', 'jbhuang0604 / awesome-computer-vision': 'https://github.com/jbhuang0604/awesome-computer-vision', 'GSA / data': 'https://github.com/GSA/data', 'GoogleTrends / data': 'https://github.com/GoogleTrends/data', 'nationalparkservice / data': 'https://github.com/nationalparkservice/data', 'fivethirtyeight / data': 'https://github.com/fivethirtyeight/data', 'beamandrew / medical-data': 'https://github.com/beamandrew/medical-data', 'src-d / awesome-machine-learning-on-source-code': 'https://github.com/src-d/awesome-machine-learning-on-source-code', 'igrigorik / decisiontree': 'https://github.com/igrigorik/decisiontree', 'keon / awesome-nlp': 'https://github.com/keon/awesome-nlp', 'openai / gym': 'https://github.com/openai/gym', 'aikorea / awesome-rl': 'https://github.com/aikorea/awesome-rl', 'umutisik / Eigentechno': 'https://github.com/umutisik/Eigentechno', 'jpmckinney / tf-idf-similarity': 'https://github.com/jpmckinney/tf-idf-similarity', 'scikit-learn-contrib / lightning': 'https://github.com/scikit-learn-contrib/lightning', 'gwding / draw_convnet': 'https://github.com/gwding/draw_convnet', 'scikit-learn / scikit-learn': 'https://github.com/scikit-learn/scikit-learn', 'tensorflow / tensorflow': 'https://github.com/tensorflow/tensorflow', 'activeloopai / deeplake': 'https://github.com/activeloopai/deeplake'}\n"
     ]
    }
   ],
   "source": [
    "# Extract information for each project\n",
    "project_list = {}\n",
    "for proj in projects:\n",
    " proj_name = proj.text # Project name\n",
    " # Find the <a> tag inside each project\n",
    " link_element = proj.find_element(By.XPATH,\".//a\") # Find the <a> tag within the project element\n",
    " '''\n",
    " Pake find_element soalnya <a> cuman ada satu.\n",
    "proj.text = Extract the raw text from the element x\n",
    "proj.get_attribute(\"y\") = Extract the value in attribute y from element x\n",
    " '''\n",
    " proj_url = link_element.get_attribute('href')  # Get the href attribute (URL)\n",
    " project_list[proj_name] = proj_url\n",
    "\n",
    " print(project_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "af782909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c211095",
   "metadata": {},
   "source": [
    "# Step 3 Save the data to CSV using Pandas\n",
    "Now that we have the data stored in Python dictionary, we will generate Pandas table from the dictionary and export CSV file.\n",
    "\n",
    "We can convert the dictionary to Pandas DataFrame using this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "83b39ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                 0\n",
      "apache / spark                                                     https://github.com/apache/spark\n",
      "apache / hadoop                                                   https://github.com/apache/hadoop\n",
      "jbhuang0604 / awesome-computer-vision            https://github.com/jbhuang0604/awesome-compute...\n",
      "GSA / data                                                             https://github.com/GSA/data\n",
      "GoogleTrends / data                                           https://github.com/GoogleTrends/data\n",
      "nationalparkservice / data                             https://github.com/nationalparkservice/data\n",
      "fivethirtyeight / data                                     https://github.com/fivethirtyeight/data\n",
      "beamandrew / medical-data                               https://github.com/beamandrew/medical-data\n",
      "src-d / awesome-machine-learning-on-source-code  https://github.com/src-d/awesome-machine-learn...\n",
      "igrigorik / decisiontree                                 https://github.com/igrigorik/decisiontree\n",
      "keon / awesome-nlp                                             https://github.com/keon/awesome-nlp\n",
      "openai / gym                                                         https://github.com/openai/gym\n",
      "aikorea / awesome-rl                                         https://github.com/aikorea/awesome-rl\n",
      "umutisik / Eigentechno                                     https://github.com/umutisik/Eigentechno\n",
      "jpmckinney / tf-idf-similarity                     https://github.com/jpmckinney/tf-idf-similarity\n",
      "scikit-learn-contrib / lightning                 https://github.com/scikit-learn-contrib/lightning\n",
      "gwding / draw_convnet                                       https://github.com/gwding/draw_convnet\n",
      "scikit-learn / scikit-learn                           https://github.com/scikit-learn/scikit-learn\n",
      "tensorflow / tensorflow                                   https://github.com/tensorflow/tensorflow\n",
      "activeloopai / deeplake                                   https://github.com/activeloopai/deeplake\n"
     ]
    }
   ],
   "source": [
    "# Extracting Data\n",
    "project_df = pd.DataFrame.from_dict(project_list, orient= 'index') \n",
    "print(project_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71f143d",
   "metadata": {},
   "source": [
    "You can see that we have to fix this a little bit to have appropriate column names. We can do it using the following code:\n",
    "\n",
    "__Reminder__ : DON'T RE-RUN THE CODE IF YOU DON'T WANT TO MAKE THE ```project_name``` INTO INT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4c7a108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          project_url  \\\n",
      "0                     https://github.com/apache/spark   \n",
      "1                    https://github.com/apache/hadoop   \n",
      "2   https://github.com/jbhuang0604/awesome-compute...   \n",
      "3                         https://github.com/GSA/data   \n",
      "4                https://github.com/GoogleTrends/data   \n",
      "5         https://github.com/nationalparkservice/data   \n",
      "6             https://github.com/fivethirtyeight/data   \n",
      "7          https://github.com/beamandrew/medical-data   \n",
      "8   https://github.com/src-d/awesome-machine-learn...   \n",
      "9           https://github.com/igrigorik/decisiontree   \n",
      "10                https://github.com/keon/awesome-nlp   \n",
      "11                      https://github.com/openai/gym   \n",
      "12              https://github.com/aikorea/awesome-rl   \n",
      "13            https://github.com/umutisik/Eigentechno   \n",
      "14    https://github.com/jpmckinney/tf-idf-similarity   \n",
      "15  https://github.com/scikit-learn-contrib/lightning   \n",
      "16             https://github.com/gwding/draw_convnet   \n",
      "17       https://github.com/scikit-learn/scikit-learn   \n",
      "18           https://github.com/tensorflow/tensorflow   \n",
      "19           https://github.com/activeloopai/deeplake   \n",
      "\n",
      "                                       project_name  \n",
      "0                                    apache / spark  \n",
      "1                                   apache / hadoop  \n",
      "2             jbhuang0604 / awesome-computer-vision  \n",
      "3                                        GSA / data  \n",
      "4                               GoogleTrends / data  \n",
      "5                        nationalparkservice / data  \n",
      "6                            fivethirtyeight / data  \n",
      "7                         beamandrew / medical-data  \n",
      "8   src-d / awesome-machine-learning-on-source-code  \n",
      "9                          igrigorik / decisiontree  \n",
      "10                               keon / awesome-nlp  \n",
      "11                                     openai / gym  \n",
      "12                             aikorea / awesome-rl  \n",
      "13                           umutisik / Eigentechno  \n",
      "14                   jpmckinney / tf-idf-similarity  \n",
      "15                 scikit-learn-contrib / lightning  \n",
      "16                            gwding / draw_convnet  \n",
      "17                      scikit-learn / scikit-learn  \n",
      "18                          tensorflow / tensorflow  \n",
      "19                          activeloopai / deeplake  \n"
     ]
    }
   ],
   "source": [
    "# Checking the index\n",
    "#print(project_df.index)\n",
    "\n",
    "# Manipulate the table\n",
    "project_df['project_name'] = project_df.index\n",
    "project_df.columns = ['project_url', 'project_name']\n",
    "project_df = project_df.reset_index(drop=True)\n",
    "# Display\n",
    "print(project_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be5ef3b",
   "metadata": {},
   "source": [
    "For the last step, we can save this DataFrame as CSV file using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "48eee529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export project dataframe to CSV\n",
    "project_df.to_csv('project_list.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60acd256",
   "metadata": {},
   "source": [
    "# [Tip] Speed up web scraping with parallelization\n",
    "As mentioned earlier that you can do web scrape faster by scraping many pages at the same time. You can use the ‘concurrent’ library in Python to accomplish this.\n",
    "\n",
    "Here is the example code for doing parallelization in web scraping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a463475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import concurrent.futures\n",
    "def scrape_url(url):\n",
    " new_browser = create_webdriver()\n",
    " new_browser.get(url)\n",
    " \n",
    " # Extract required data here\n",
    " # ...\n",
    " \n",
    " new_browser.quit()\n",
    " \n",
    " return data\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=4) as executor:\n",
    " future_results = {executor.submit(scrape_url, url) for url in urlarray}\n",
    "\n",
    "results = []\n",
    " for future in concurrent.futures.as_completed(future_results):\n",
    " results.append(future.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d611eb3",
   "metadata": {},
   "source": [
    "__urlarray__ = List of all URL you would like to scrape\n",
    "\n",
    "You can change __max_workers=4__ to other number. Note that this code will open 4 browser windows at the same time.\n",
    "\n",
    "As I mentioned earlier, please be mindful when scraping a website. They can block or sue you at anytime, especially when you open multiple connections to flood their websites."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
